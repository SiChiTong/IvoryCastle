<launch>
  <arg name="ns" default="scorpio/mmp0"/>

  <!--assistant related-->
  <param name="aiml_path" value="$(find ros_aiml)/data" />
  <node name="aiml_server" pkg="ros_aiml" type="aiml_server.py" output="screen"/>
  <node name="text_process" pkg="ros_aiml" type="text_process.py" output="screen"/>

  <!--vocal output related, offline-->
	<!--include file="$(find sound_play)/soundplay_node.launch"/>
	<node name="aiml_tts" pkg="ros_aiml" type="aiml_tts_client_soundplay.py" output="screen"/-->

	<!--vocal output related, online-->
	<node name="aiml_tts" pkg="ros_aiml" type="aiml_tts_client_google.py" output="screen"/>

  <!--vocal input related-->
  <node name="google_speech_recog" pkg="ros_aiml" type="robot.py" output="screen"/>

  <!--navigation related-->
  <node name="tfServer" pkg="ira_factory_state_machine" type="tfServer.py" output="screen"/>
  <node name="dpmcT" pkg="pmc_navigation" type="dpmcT.py" args="$(arg ns)"/>
  <node pkg="leg_detector" type="leg_detector" name="leg_detector" args="scan:=$(arg ns)/front_scan $(find leg_detector)/config/trained_leg_detector.yaml" output="screen"/>
  <node pkg="leg_detector" type="leg_detector2" name="leg_detector2" args="scan:=$(arg ns)/back_scan $(find leg_detector)/config/trained_leg_detector.yaml" output="screen"/>
  <node name="humancaution" pkg="pmc_navigation" type="humancaution.py" args="$(arg ns)"/>
</launch>
